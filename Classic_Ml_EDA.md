## Часть1

https://habr.com/ru/amp/publications/752434/
#### Визуализация данных
При формировании EDA (exploratory data analysis) используются библиотеки Pandas работы с табличными данными (CSV, Excel ...), в описанном примера брали данные графиков из библиотеки Seaborn или  Matplotlib. Разберем примеры описанные в статье:

Начинаем с обработки CSV файла: 

Загружаем на чтение и выводим первые пять или последние 5 строк из нашего dataset
' df = pd.read_csv(url) '
' df.head() 
' df.tail() 

Данные есть, теперь можем проводить дальнейший анализ
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html
' df.info()
' df.shape
' df.isna().sum() - df.isna().mean() * 100 - df.isna().any().any()

В EDA:
1. Проверяют типы данных
2. Приводят числовые признаки к числам
3. **Только потом** проверяют `isna()`

Так при работе с dataset выяснилось, что некоторые columns имеют разные признаки (разные Dtype)

![[Pasted image 20260208172454.png]]

Поэтому и isna показывает вывод 0 по пропускам: 

![[Pasted image 20260208172614.png]]

Приводим к одному типу:
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html
Числовые
' df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
coerce - принуждать -> значение, которое не переводится меняется на NaN 
Бинарные
' df = df.replace({"Yes": 1, "No": 0}) - так делать не надо, потеряешь данные 
Остальные категориальные
' df = pd.get_dummies(df, drop_first=True) - это тоже странно 

**Признак стал `float64`, потому что pandas не может хранить `NaN` в целочисленном (`int`) типе** - это надо проверять 
![[Pasted image 20260208174755.png]]

Выбираем категориальные: 
' categorical_cols = df.select_dtypes(include="object").columns -  это хорошо
' df[categorical_cols].isna().sum()
' df[categorical_cols].apply(lambda x: x.str.strip() == "").sum()

Подсчитывает количество уникальных значений в Series или в определённом столбце DataFrame. Результатом работы метода является Series, где индексами служат уникальные значения, а значениями — частота их появления, по умолчанию отсортированная по убыванию

' df[target].value.counts(normilize = "True")  

' 

ура, пропуск:

![[Pasted image 20260208180903.png]]

Теперь нужно **заполнить пропуски**, но **уже после train/test split**, чтобы не было утечки данных.



## Часть2

EDA
 └─ нашли типы, NaN

PREPROCESSING
 ├─ отделили X / y
 ├─ split по строкам (stratify=y)
 ├─ обработка N
 ├─ кодирование категорий
 └─ масштабирование (если нужно)
 
1) Выделение target
2) Анализ баланса классов
3) Train/Test split (stratify)
4) Определение типов признаков
5) Pipeline:
      - SimpleImputer - Пропуски для каждого столбца свое
      - OneHotEncoder - Преобразует категории в бинарные признаки. 
      https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html
6) ColumnTransformer 
7) KFold для CV


11/02
Продолжаем, изучать EDA. LВ начале выполнения у нас уже есть dataset, найденные числовые пропуски у признака TotalCharges. Так, строю Pipline для выбора данных по категориям их заполнения после разбиения Test/Train. 

' df.drop(column='target') 
' df[target]

Делаем разбивку. И тут самое интересное: sklearn, не делаеь явное деление на 3, train test slit. 
Сначала делаем split для проверки в конце, а потом CV для train данных. Вот такие дела, поэтому делем метод: train_test_split()

Делаем обработку NaN

SimpleImputer: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html
- `strategy`
    - `"mean"`
    - `"median"`
    - `"most_frequent"`
    - `"constant"`
- `fill_value` (если strategy="constant")

Делаем решающее дерево: 
https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html
Просто добавли в пайплайн (хотя конечно можно играться с параметрами): 
![[Pasted image 20260211170208.png]]
Получается пайплайн в пайплане, очень удобно, будто наследуешь класс от класса
![[Pasted image 20260211171317.png]]

Подведем итоги.

Задача:
бинарная классификация (Churn). Мы предсказываем, уйдёт клиент или нет. Положительный класс  уход клиента. Что у ас интересное было на EDA & PREPROCESSING
- Корректное выделение целевой переменной. Target нельзя оставлять среди признаков, иначе возникает утечка данных. Модель не должна «видеть» правильный ответ в обучающих данных.
 - В задачах оттока почти всегда есть дисбаланс: клиентов, которые остаются, больше, чем тех, кто уходит. Поэтому accuracy не является надёжной метрикой. Можно получить высокую accuracy, просто предсказывая «не уйдёт» для всех.
 - Стратифицированное разделение данных. При train/test split обязательно использовать стратификацию, чтобы доля классов сохранялась и в обучающей, и в тестовой выборке. Иначе оценка модели будет нестабильной и может исказиться.
- Preprocessing должен выполняться только на обучающей выборке. Все преобразования (заполнение пропусков, кодирование категорий) должны быть встроены в Pipeline, чтобы избежать data leakage.
- Для числовых признаков использовали заполнение медианой. Это устойчиво к выбросам и подходит для финансовых данных. Для категориальных признаков — заполнение наиболее частым значением и One-Hot Encoding. One-Hot Encoding резко увеличивает размерность данных. После кодирования получается разреженная матрица, потому что большинство значений нули. Это нормально и эффективно по памяти.

Decision Tree:
Дерево решений строит модель через последовательные разбиения по признакам. Мы ограничили глубину дерева до 5. 

При оценке модели важно различать предсказанные классы и вероятности. Метод predict возвращает финальное решение (класс), а predict_proba возвращает вероятность принадлежности к каждому классу. Accuracy и F1 считаются по классам, ROC-AUC считается по вероятностям (тут прям задумался). 

ROC-AUC особенно важен для задач с дисбалансом, потому что он оценивает качество ранжирования, а не жёсткие решения при пороге 0.5. Это позволяет понять, насколько модель вообще способна отделять уходящих клиентов от остающихся.

Важно!!!
Также важно правильно определить положительный класс при расчёте F1. Если target хранится как строки («Yes»/«No»), нужно явно указать, какой класс считается положительным, иначе возникает ошибка.

Финальный workflow (что и ваше прописывал ). выделение target, анализ баланса классов, стратифицированный train/test split, построение preprocessing через Pipeline, обучение Decision Tree с ограниченной глубиной, оценка через Accuracy, F1 и ROC-AUC.


Вывод пор метрикам: 

Было обучено дерево решений с ограничением глубины до 5.  
Модель показала ROC-AUC ≈ 0.83 на тестовой выборке.  
Средний ROC-AUC по 5-fold StratifiedKFold составил 0.827 с низким стандартным отклонением (0.0096), что свидетельствует о стабильности модели и отсутствии выраженного переобучения.

Accuracy ≈ 0.80 и F1 ≈ 0.60 подтверждают, что модель способна выявлять клиентов с риском ухода.

Особенное внимание методы: cross_val_score()
https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html

